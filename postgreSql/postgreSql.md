- [**Concepts**](#concepts)
  - [**Data Modelling**](#data-modelling)
    - [**Relationships in Data Modelling**](#relationships-in-data-modelling)
    - [**Referencing/normalizing vs. Embedding/denormalizing**](#referencingnormalizing-vs-embeddingdenormalizing)
      - [**Referencing/normalizing**](#referencingnormalizing)
        - [**Child referencing**](#child-referencing)
        - [**Parent referencing**](#parent-referencing)
        - [**Two-way referencing**](#two-way-referencing)
      - [**Embedding/denormalizing**](#embeddingdenormalizing)
    - [**Time to make a decision**](#time-to-make-a-decision)
    - [**Summary**](#summary)
  - [**Object storage**](#object-storage)
    - [**How it works**](#how-it-works)
      - [**A deeper look**](#a-deeper-look)
    - [**Benefits**](#benefits)
      - [**Storing/managing unstructured data**](#storingmanaging-unstructured-data)
      - [**Scalability**](#scalability)
      - [**Reduced complexity**](#reduced-complexity)
      - [**Customizable metadata**](#customizable-metadata)
    - [**Object vs. File vs. Block storage**](#object-vs-file-vs-block-storage)
      - [**File storage**](#file-storage)
      - [**Object storage**](#object-storage-1)
      - [**Block storage**](#block-storage)
    - [**User cases**](#user-cases)
- [**Working with PostgreSQL**](#working-with-postgresql)
  - [**Creating a new table**](#creating-a-new-table)
  - [**Removing a new table**](#removing-a-new-table)
  - [**Populating a table with rows**](#populating-a-table-with-rows)
  - [**Querying a table**](#querying-a-table)
    - [**Retrieve all rows**](#retrieve-all-rows)
    - [**Retrieve with qualification**](#retrieve-with-qualification)
      - [**`SELECT`**](#select)
      - [**`ORDER`**](#order)
      - [**`DISTINCT`**](#distinct)
    - [**Join queryies**](#join-queryies)
      - [**Outer joins**](#outer-joins)
        - [**Left outer join**](#left-outer-join)
        - [**Self outer join**](#self-outer-join)
  - [**Aggregate functions**](#aggregate-functions)
    - [**Aggregates with grouping**](#aggregates-with-grouping)
      - [**Filtering output rows of aggregates**](#filtering-output-rows-of-aggregates)
        - [**`HAVING`:**](#having)
        - [**`LIKE`:**](#like)
      - [**Filtering input rows of aggregates**](#filtering-input-rows-of-aggregates)
        - [**`FILTER`:**](#filter)

# **Concepts**

PostgreSQL is a relational database management system. It means that it is a system for managin data stored in _relations_, and by relations we mean _tables_.

Each table is a named collection of _rows_. Each row of a given table has the same set of named _columns_, and each column is of a specific data type.

Columns have a fixed order in each row, but SQL does not guarantee the order of rows within a table.

Tables are grouped into databases, and a collection of databases managed by a single PostgreSQL server instance consititutes a database _cluster_.

## **Data Modelling**

Data modelling is the process of taking unstructured data, generated by a real-world scenario, and structure it into a logical data model using some criteria.

Data models are made up of entities, which are the objects or concepts we want to track data about, and they become the tables in a database. Products, vendors, and customers are all examples of potential entities in a data model. Entities have attributes, which are details we want to track about entities — you can think of attributes as the columns in a table. If we have a product entity, the product name could be an attribute.

Entities don’t exist in isolation; they’re connected to each other. The connections between entities in a data model are called relationships, and relationships reflect business rules.

Modelling data is not always straight forward. Sometimes there are simply no right answers. So in these situations there is not a unique way of structuring data. So to make it a bit easier let's understand a bit more about these concepts:

1. Different types of relationships between data.
2. Referncing/normalization vs. embedding/denormalization.
3. Deciding about embedding documents or referencing them.
4. Different types of referencing.

### **Relationships in Data Modelling**

Relational databases consist of **tables**, **columns**, **rows**, **keys**, and **relationship** between tables. There are three types of relationships between the tables:

1. **one to one:** One to one relationship means one entity in a table is related to just one entity in another table. It should be rare in any relational database design. For instance, each student has only one address and each address represents one student. This type of relationship is usually not very important in terms of data modelling. But it is important to understand that One-to-one relationships also occur when a business needs to use entities that are **supertypes** and **subtypes**, also called parents and children. For example, a product could be a supertype, and a specific kind of product, like a book, could be the subtype. In some situations, there are good reasons for storing general product data in a separate table from more specific data about books, and this can help in representing hierarchical relationships among entities. In this example, a single book title should be associated with a single product ID number, and vice versa, making this a one-to-one relationship between products and books.
2. **one to many:** One to many relationship means one entity in a table is related to one or many entities in another table. A one to many relationship should be the norm in any relational database design and is found in all relational database environments. For example, each customer has one or more orders.

> This type of relationship is so important that in document-based databases like MongoDB it is actually separated into 3 sub-types: **one to few (1:few)**, **one to many (1:many)**, **one to ton (1:ton)**. The idea is based on the relative amount of the many. Let's think of an example. One movie can win many awards, but actually just a few. A movie will never win a thousand awards. This represents a 1:few relationship. From a different point of view, a movie can have hundreds or thousands of reviews. This represents a 1:many relationship. As another example, think of the number of logs that an application generates. So the application's logs can grow to millions. This represents a 1:ton relationship. The difference between 1:many and 1:ton is a bit fuzzy, but you can consider it like this: If something can grow almost to infinity, that would be a sign of a 1:ton relationship. Remember that in relation databases there is just a 1:many relationship without quantifying how much the many actually is. But in document-based databases like MongoDB, this is an important factor based on which we decide to normalize or denormalize data.

3. **many to many:** Many to many relationship means multiple entities in a table can be associated with more than one entity in another table. For instance, each student can attend many courses and, each course can consist of many students. Books and authors are also a great example of this relationship — one author can write multiple books, and a single book can be written by multiple authors. You can also think of movies and actors. So a movie can have many actors, and an actor can play in many movies. Although many-to-many relationships exist, you don’t actually see them in data models. Instead, we use associative entities, which are tables that break the many-to-many relationship into many-to-one relationships. In this case, you might have a books table, an authors table, and an author-book table to link the two.

> Many to many relationship causes **duplications** in database. Duplications cause false results from queries. For instance, a company produces products, which consist of several components. One product is made up of many components, and one component can be in more than one product. There is a way to prevent the duplication while setting many to many relationship. The solution is creating a totally new table known as bridge table or **join table**.

### **Referencing/normalizing vs. Embedding/denormalizing**

#### **Referencing/normalizing**

An introduction to data modeling would not be complete without mentioning the concept of normalization. Normalization is the process by which anomalies are avoided and redundancy is eliminated, and the concept was first suggested by a data scientist named _Edgar Codd_. Normalizing a data model means structuring data so that each entity only has one theme or topic. In more technical terms, we refer to this as removing **partial dependencies** and **transitive dependencies**.

For example, I want to store data about customer purchases. I’ll want to know information like the dollar amount purchased, the customer name, and the store where the purchase took place. I could store all of these data points in a single table, but that would lead to problems. For example, a customer who has made hundreds of purchases may get married and change her name. To reflect that change in my records, I would have to go through my table and change her name for every single purchase she’s ever made. Instead of dealing with hundreds of changes, a normalized data model would allow me to make only one change. In this situation, I should store customer data in a customer table, product data in a product table, store data in a store table, and so on. By using primary keys and foreign keys, I can link these tables together and access all the information I need. Better yet, when I need to change a customer’s name, I only have to make the change in one place.

When we normalize data, the connection of one entity to another is established by IDs. For instance, a _movies_ table will have ID references to an _actors_ table. This is why normalizing is also called referencing. This specific type of referencing is called **child referencing**. It creates some sort of hierarchy.

On the other hand, the _actors_ table would probably have ID references to the _movies_ table. This is called **parent referencing**.

Now imagine we want to query all the information of a specific movie. For any refernce in the movie data, an additional query should be done to get the information, for example for actors of that movie. This will reduce **performance**. However, it gives us the ability to query actors information on its own.

##### **Child referencing**

If we want to implement child referencing we should keep 2 things in mind. If the number of children can potentially grow to a very huge number, we should probably use parent referencing instead. Also remember that child referencing makes it so that parents and children are very tightly coupled. This is not always what we want. This is where parent referncing comes into play.

> Use child referencing when you have a 1:few relationship where we know beforehand that the array of children data will not grow much.

##### **Parent referencing**

While in child referncing, only the parent know about its children, in parent referncing, the children know about their parent. The parent will have no idea about how many children it has and what they are. In each child data, we keep a reference to the parent element. For example, think of the example we mentioned about an application and its logs. So if we used child referencing, the application data would have to hold millions of ID refernces pointing to each log. So the application data volume would grow to infinity and that is definitely not good. On the other hand, with parent referencing, each log data would have a reference ID to the parent application data. This way, no data will grow to infinity.

> Use parent referencing when you have 1:many or 1:ton relationships where the array of children data can potentially grow to infinity.

##### **Two-way referencing**

Going back to the example of movies and actors, we usually use two-way referencing for many:many relationships. In each movie, we keep reference IDs of its actors, and at the same time, we keep reference IDs of the movies in which the actor has played. This makes it easy to query movies and actors completely independantly.

#### **Embedding/denormalizing**

Going back to the movie example mentioned for referncing/normalizing, if we store the actors data of a movie in the movie data, we are actually embedding/denormalizing. This gives us a much better **performance** since we can get all the information of a movie in one query. But we can no longer query the actors information on its own.

> When thinking about modelling our data, we usually start with having everything normalized, and then in specific situations we come to conclusion that it is best to embed/denormalize data in some situations.

### **Time to make a decision**

When we have 2 related datasets, we have to decide whether to embed one into another, or keep them separated and put a reference from one to another. We use 3 criteria to make this decision altogether, we don't use just one of them to make the decision.

| Criteria             | Embedding                       | Referencing                                  |
| -------------------- | ------------------------------- | -------------------------------------------- |
| Relationship type    | _1:few_, _1:many_               | _1:many_, _1:ton_, _many:many_               |
| Data access patterns | high _read/write_               | high _write/read_ (data is updated a lot)    |
| Data closeness       | datasets really belong together | datasets are frequently queried on their own |

> In a 1:many relationship, it is ok to either embed or reference. This is where the 2nd and 3rd criteria comes to help.

### **Summary**

- The most important principle is: Structure your data to match the ways that your application **queries** and **updates** data: identify the questions that arise from your application's use cases first, and then model your data so that the questions can get answered in the most efficient way. For instance, will I need to query movies and actors always together? or are there scenarios where I would need to query them independantly?
- Always favor **embedding**, unless there is a good reason not to embed. So you may use embedding on _1:few_ and _1:many_ relationships. A _1:ton_ or a _many:many_ relationship is usually a good reason to **reference** instead of embedding.
- Favor referncing when data is **updated** a lot and if you need to frequently **access** a dataset on its own. On the other hand, use embedding when data is mostly **read** but rarely updated, and when two datasets belong intrinsically together.
- Don't allow arrays to grow indefinitely. Therefore, if you need to normalize, use **child referencing** for _1:many_ relationships, and **parent referencing** for _1:ton_ relationships. Use two-way referencing for _many:many_ relationships.

## **Object storage**

Object storage (AKA object-based storage) is a data storage architecture for handling large amounts of unstructured data. This is data that does not conform to, or cannot be organized easily into, a traditional relational database with rows and columns. Today's internet communications data is largely unstructured, including email, video, photos, web pages, audio files, sensor data, and other types of media and web content.

Enterprises are finding it challenging to efficiently (and affordably) store and manage this unprecedented volume of data. Object-based storage has emerged as the preferred method for **data archiving and backup**. It offers a level of **scalability** not possible with traditional file or block-based storage. With object storage you can store and manage data volumes on the order to terabytes, petabytes, and even greater.

### **How it works**

Objects are discrete units of data that are stored in a structurally flat data environment. There are no folders, directories, or complex hierarchies as in a file-based system. Each object is a simple, self-contained repo that includes the data, metadata (descriptive information associated with an object), and a unique ID number (instead of a filename and filepath). You can aggregate object storage devices into larger storage pools and distribut these storage pools across locations. This allows for unlimited **scale**, as well as improved **data resiliency** and **disaster recovery**.

Objects (data) in an object-storage system are accessed via APIs. The native API for object storage is an HTTP-based RESTful API. These APIs query an object's metadata to locate the desired object (data) via the internet from anywhere, on any device.

Additional RESTful API standards are emerging that go beyond creating, retrieving, updating, and deleting objects. These allow applications to manage the object storage, its containers, accounts, multi-tenancy, security, billing, and more.

For example, if you want to store all the books in a very large library system on a single platform, you will need to store the contents of the book (data), but also the associated information like the author, publication data, publisher, subject, copyrights, and other details (metadata).

You could store all of this data and metadata in a relational database, organized in folders under a hierarchy of directories and subdirectories. But with millions of books, the search and retrieval process will become cumbersome and time-consuming. An object storage system works well here, since the data is static or fixed; The content of the book will not change. Objects (data, metadata, and ID) are stored as packages in a flat structure and easily located and retrieved with a single API call. Further, as the number of books continue to grow, you can aggregate storage devices into larger storage pools, and distribute these storage pools for unlimited scale.

#### **A deeper look**

We learned that you can use simple API calls to upload and retrieve files in an object storage system. But an application also needs the object's metadata in order to locate the proper object in storage. This is where an object storage database comes into play. This database provides a directory or sorts that uses the object's metadata to locate the appropriate data files in a distributed storage system.

Each object storage group has an object storage database that contains 2 tables:

1. **Object directory table:** contains descriptive information about each object (metadata). This directory keeps track of all objects in the storage hierarchy by recording the collection ID, the object name, and other pertinent information.
2. **Object storage table:** contains the data content/file itself (objects). The data (fixed digital content such as video and image files or large libraries of documents) sits in the object store, while the metadata resides in a database/object directory table.

When an application `POST`s a file, it creates the metadata and stores it in the object directory table within the object storage database, along with putting the file to the object storage table. To retrieve the file later, the application queries the object directory/database for the metadata and uses that descriptive, identifying information to locate or `GET` the data.

### **Benefits**

#### **Storing/managing unstructured data**

Object storage is seeing wide adoption in the eral of cloud computing and for the management of unstructured data which is estimated to represent the vast majority of all data worldwide in the near future. The volume of web-generated content - emails, videos, social media, documents, sensor data produced by IoT devices - is massive and growing. Unstructured data is typically **static** (unchanging) by may be required at anyu time, anywhere.

Could-based object storage is ideal for long-term data retention. Use object storage to replace traditional archives, such as Network Attached Storage (NAS), reducing your IT infrastructure. Easily archive and store mandated, regulatory data that must be retained for extended periods of time. Cost-effectively preserve large amounts of rich media content (images, videos, etc.) that is **not frequently accessed**.

#### **Scalability**

Unlimited scale is the most significant advantage of object-based storage. You can simply add more devices/servers in parallel to an object storage cluster for additional processing and to support the higher throughputs required by large files such as videos or images.

#### **Reduced complexity**

Objects storage removes the complexity that comes with a hierarchical file system with folders and directories. There is less potential for performance delay and you will realize efficiencies when retrieving data since there are no folders, directories or complex hierarchies to navigate. This shines particularly when managing very large quantities of data.

#### **Customizable metadata**

Objects use metadata for important functions such as policies for retention, deletion and routing, disaster recovery strategies (data protection), or validating content authenticity. You can also customize the metadata with additional context that can be later extracted and leveraged to perform business insights and analytics around customer service or market trends.

### **Object vs. File vs. Block storage**

Storage methods have evolved to meet the changing nature of data. Data can be transactional and collected in smaller volumes that are neatly stored in a database on a dis drive on a server. File-based storage and block-based storage are well-suited to this type of structured data and continue to work well in certain scenarios. But the Internet has changed everything in a way that organizations now struggle to manage mounting volumes of web-based, digital content (unstructured data).

#### **File storage**

Organizes and stored data inside a folder. Files are named, tagged with metadata (typically the file name, file type, creation data and last updating time) and organized in folders under a hierarchy of directories and subdirectories. A hierarchical storage system like this works well with relatively small, easily organized amounts of data. However, as the number of files grow, the search and retreival process can become cumbersome and time-consuming.

#### **Object storage**

Does not use folders, directories or complex hierarchies. Rather, each object is a simple, self-contained repo that includes the data, metadata, and a unique identifying ID number that an application uses to locate and access it. In this case, the metadata is **more descriptive** than with a file-based approach. You can customize the metadata with additional context that you can later extract and leverage for other purposes, such as data analytics.

Use object storage as a solution if you require cost-effective storage capacity for your unstructured data scaling far past the effective limits of block and file solutions. Object storage is also ideal for archiving data that does not change frequently or at all (static files), such as transaction records or music, image, and video files.

#### **Block storage**

Block storage is an alternative to file-based storage - one with improved efficiency and performance. Block storage breaks a file into equally-sized chunks of data and stores data blocks separately under a unique address. You won't need a file-folder structure. Instead, you store the collection of blocks anywhere in the system for maximum efficiency.

To access a file, a server operating system uses the unique address to pull the blocks back together, assembling them into the file. This will provide you with efficiency as the system does not need to navigate through directories and file hierarchies to access the data blocks. Block storage works well for critical business applications, transactional databases and virtual machines that require low-latency, granular or more detailed access to data, and consistent performance.

### **User cases**

1. **Cloud-native applications:** Collect and store large amounts of unstructured IoT and mobile data for your smart device applications. Easily and efficiently update your application components.
2. **AI and big data analytics**

# **Working with PostgreSQL**

## **Creating a new table**

This is the syntax you need to create a new table:

```sql
CREATE TABLE weather (
    city            varchar(80),
    temp_lo         int,           -- low temperature
    temp_hi         int,           -- high temperature
    prcp            real,          -- precipitation
    date            date
);
```

PostgreSQL supports the standard SQL types:

| Type             | Description                                                        |
| ---------------- | ------------------------------------------------------------------ |
| varchar(N)       | stores arbitrary character strings up to `N` characters in length. |
| char(N)          | -                                                                  |
| int              | the normal integer type.                                           |
| smallint         | -                                                                  |
| real             | stores single precision floating-point numbers.                    |
| double precision | -                                                                  |
| date             | stores date.                                                       |
| point            | A PostgreSQL-specific data type that stores geographical location. |

> PostgreSQL can be customized with an arbitrary number of user-defined data types. Consequently, type names are not key words in the syntax, except where required to support special cases in the SQL standard.

> White space (i.e., spaces, tabs, and new lines) can be used freely in SQL commands.

> Two dashes (--) introduces comments

> SQL is case insensitive about key words and identifiers, except when identifiers are double-quoted to preserve the case.

## **Removing a new table**

If you don't need a table any longer or you want to recreate it differently, you can remove it using the following command:

```sql
DROP TABLE <tablename>;
```

## **Populating a table with rows**

The `INSERT` statement is used to insert rows into a table:

```sql
INSERT INTO weather VALUES ('Mashhad', 31, 40, 0.25, '1402-04-30');
```

> All data types use rather obvious input formats. Constants that are not simple numeric values should usually be surrounded by single quotes ('). The `date` type is actually very flexible in what it accepts.

The syntax mentioned above requires you to remember the order of columns. But you can use the syntax below to list the column order explicitly.

```sql
INSERT INTO weather (city, temp_lo, temp_hi, prcp, date)
  Values ('Mashhad', 31, 40, 0.25, '1402-04-30')
```

> You may also omit a column, for instance, the 'prcp', if it is unknown data.

You could also use the `COPY` command to load large amounts of data from flat-text files. The COPY command is optimized for this application, although it allows less flexibility than `INSERT`.

```sql
COPY weather from '/home/user/weather.txt';
```

## **Querying a table**

The `SELECT` statement is used to query a table. The statement is divided into:

1. **Select list:** the part that lists the columns to be returned.
2. **Table list:** the part that lists the tables from which to retrieve data
3. **Optional qualification:** the part that specifies any restrictions

### **Retrieve all rows**

To retrieve all rows of a table:

```sql
SELECT * FROM weather;
```

> `*` is a shorthand for 'all columns'. It is widely considered bad code, since adding a column to the table would change the resutl. You could also do it like this:

```
SELECT city, temp_lo, temp_hi, prcp, date FROM weather;
```

In this case, we expect this output:

```sql
     city      | temp_lo | temp_hi | prcp |    date
---------------+---------+---------+------+------------
 San Francisco |      46 |      50 | 0.25 | 1994-11-27
 San Francisco |      43 |      57 |    0 | 1994-11-29
 Hayward       |      37 |      54 |      | 1994-11-29
(3 rows)
```

You can write **expressions**, not just simple column references, in the select list.

```sql
SELECT city, (temp_hi+temp_lo)/2 AS temp_avg, date FROM weather;
```

In this case, we expect this output:

```sql
     city      | temp_avg |    date
---------------+----------+------------
 San Francisco |       48 | 1994-11-27
 San Francisco |       50 | 1994-11-29
 Hayward       |       45 | 1994-11-29
(3 rows)
```

### **Retrieve with qualification**

#### **`SELECT`**

A query can be _qualified_ by adding a `WHERE` caluse that specifies which rows are wanted. The clause contains a Boolean expression, and only rows for which the Boolean expression is true are returned. The usual Boolean operators (`AND`, `OR`, and `NOT`) are allowed in the qualification.

```sql
SELECT * FROM weather
    WHERE city = 'San Francisco' AND prcp > 0.0;
```

In this case, we expect this output:

```sql
     city      | temp_lo | temp_hi | prcp |    date
---------------+---------+---------+------+------------
 San Francisco |      46 |      50 | 0.25 | 1994-11-27
(1 row)
```

#### **`ORDER`**

You can request that the results of a query be returned in sorted order.

```sql
SELECT * FROM weather
    ORDER BY city, temp_lo;
```

#### **`DISTINCT`**

You can request that duplicate rows be removed from the result of the query.

```sql
SELECT DISTINCT city
    FROM weather;
```

This can be used along with the `ORDER` statement:

```sql
SELECT DISTINCT city
    FROM weather
    ORDER BY city;
```

### **Join queryies**

Queries can access multiple tables at once, or access the same table in such a way that multiple rows of the table are being processed at the same time. Queries that access multiple tables or multiple instances of the same table at one time are called _join queries_.

Join queries combine rows from one table with rows from a second table, with an expression specifying which rows are to be paired.

We have two types of joins: **inner joins** and **outer joins**.

```sql
SELECT * FROM weather JOIN cities ON city = name;
```

> We can also relabel tables in the command:

```sql
SELECT * FROM weather w JOIN cities c ON w.city = c.name;
```

> This command will ignore any row on the 'weather' table the 'city' column of which does not match any 'name' column on the 'city' table. In the exmple above, the city 'hayward' has its row on the weather table, but not on the cities table. This can be fixed by implementing an outer join.

> We are very likely to receive an output where two columns hold same values. It obviously comes from the matching strategy. But we can fix this by explicitly typing the column names that should be displyed in the result:

```sql
SELECT city, temp_lo, temp_hi, prcp, date, location
    FROM weather JOIN cities ON city = name;
```

> If there are similar column names in both tables, we can specify which ones we are actually targetting:

```sql
SELECT weather.city, weather.temp_lo, weather.temp_hi,
       weather.prcp, weather.date, cities.location
    FROM weather JOIN cities ON weather.city = cities.name;
```

> It is considered good coding style to qualify all column names in a join query, so that the query won't fail if a duplicate column name is later added to one of the tables.

Join queries mentioned above can be written in the format below, but it is recommended to use the explicit syntax.

```sql
SELECT *
    FROM weather, cities
    WHERE city = name;
```

#### **Outer joins**

We have 3 different types of outer join:

1.  Left outer join
2.  Right outer join
3.  Full outer join
4.  Self join

##### **Left outer join**

In this example, we are going to use the left outer join.

```sql
SELECT *
    FROM weather LEFT OUTER JOIN cities ON weather.city = cities.name;
```

This query, as it is clear from its syntax, is called a _left outer join_. The table mentioned on the left of the join operator will have all of its rows in the output, while the table on the right side of the join operator will only have rows ouput that match a row on the left table. For rows that there was no match, empty (`null`) values are inserted for the table on the right.

##### **Self outer join**

This is used to join a table against itself. Suppose we want to find all the weather records that are in the temperature range of other weather records. We would have to compare the `temp_lo` and `temp_hi` columns of each weather row to the `temp_lo` and `temp_hi` columns of all other weather rows. This is implemented by:

```sql
SELECT w1.city, w1.temp_lo AS low, w1.temp_hi AS high,
       w2.city, w2.temp_lo AS low, w2.temp_hi AS high
    FROM weather w1 JOIN weather w2
        ON w1.temp_lo < w2.temp_lo AND w1.temp_hi > w2.temp_hi;
```

> Notice how we have relabled the table weather two times, once `w1`, and then `w2` to be able to distinguish the left and ride side of the join.

## **Aggregate functions**

An aggregate function computes a single result from multiple input rows. For example, there are aggregate functions to compute the `count`, `sum`, `avg`, `max`, and `min` over a set of rows.

For example, we can find the highest low-temperature:

```sql
SELECT max(temp_lo) FROM weather;
```

In this case, we expect this output:

```sql
max
-----
  46
(1 row)
```

To find out what city the above reading occurred in:

```sql
SELECT city FROM weather
  WHERE temp_lo = (SELECT max(temp_lo) FROM weather);
```

> This command will not work:
>
> ```sql
> SELECT city FROM weather WHERE temp_lo = max(temp_lo);
> ```
>
> aggregate functions cannot be used in the `WHERE` clause. `WHERE` clause determines which rows will be included in the aggregate calculation. To solve this, you can restate the query by using a _subquery_.
>
> ```sql
> SELECT city FROM weather
>   WHERE temp_lo = (SELECT max(temp_lo) FROM weather);
> ```
>
> The subquery is an independant computation that computes its own aggeegate separately from what is happening in the outer query.

### **Aggregates with grouping**

Aggregates are very useful in combination with `GROUP BY` clauses. For example, we can get the number of readings and the maximum low temperature observed in each city with:

```sql
SELECT city, count(*), max(temp_lo)
    FROM weather
    GROUP BY city;
```

Then we expect this output:

```sql
     city      | count | max
---------------+-------+-----
 Hayward       |     1 |  37
 San Francisco |     2 |  46
(2 rows)
```

#### **Filtering output rows of aggregates**

##### **`HAVING`:**

We can also filter the grouped rows by using `HAVING`:

```sql
SELECT city, count(*), max(temp_lo)
    FROM weather
    GROUP BY city
    HAVING max(temp_lo) < 40;
```

Then we expect this output:

```sql
  city   | count | max
---------+-------+-----
 Hayward |     1 |  37
(1 row)
```

> **IMPORTANT:** The fundamental difference between `WHERE` and `HAVING` is this: `WHERE` selects input rows before groups and aggregates are computed. This, it controls which rows go into the aggregate computation, while `HAVING` selects group rows after groups and aggregates are computed. Thus, `WHERE` must not contain aggregate functions. It makes no sense to try to use an aggregate to determine which rows wil lbe inputs to the aggregates. `HAVING` always contains aggregate functions. You are allowed to write `HAVING` that does not use aggregates, but it is seldom useful.

##### **`LIKE`:**

We can also filter the grouped rows to return only the cities whose names begin with 'S', using `LIKE`:

```sql
SELECT city, count(*), max(temp_lo)
  FROM weather
  WHERE city LIKE 'S%'
  GROUP BY city;
```

#### **Filtering input rows of aggregates**

##### **`FILTER`:**

Used to select the rows that go into an aggregate computation:

```sql
SELECT city, count(*) FILTER (WHERE temp_lo < 45), max(temp_lo)
    FROM weather
    GROUP BY city;
```

`FILTER` is much like `WHERE`, except that it removes rows only from the input of the particular aggregate function that it is attached to. Notice how the `count` aggregate counts only rows with `temp_lo` below 45, but the `max` aggregate is still applied to all rows.
